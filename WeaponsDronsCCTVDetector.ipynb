{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abdulmalikbintilas/Desktop/Flask\n"
     ]
    }
   ],
   "source": [
    "cd /Users/abdulmalikbintilas/Desktop/Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: osx-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/abdulmalikbintilas/miniconda3/envs/T5\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch::pytorch\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    brotli-python-1.0.9        |   py38he9d5cce_7         353 KB\n",
      "    certifi-2024.2.2           |   py38hecd8cb5_0         160 KB\n",
      "    filelock-3.13.1            |   py38hecd8cb5_0          22 KB\n",
      "    gmpy2-2.1.2                |   py38hd5de756_0         152 KB\n",
      "    idna-3.4                   |   py38hecd8cb5_0          96 KB\n",
      "    intel-openmp-2023.1.0      |   ha357a0b_43548         638 KB\n",
      "    jinja2-3.1.3               |   py38hecd8cb5_0         271 KB\n",
      "    markupsafe-2.1.3           |   py38h6c40b1e_0          22 KB\n",
      "    mkl-2023.1.0               |   h8e150cf_43560       181.0 MB\n",
      "    mkl-service-2.4.0          |   py38h6c40b1e_1          44 KB\n",
      "    mkl_fft-1.3.8              |   py38h6c40b1e_0         195 KB\n",
      "    mkl_random-1.2.4           |   py38ha357a0b_0         271 KB\n",
      "    mpmath-1.3.0               |   py38hecd8cb5_0         834 KB\n",
      "    networkx-3.1               |   py38hecd8cb5_0         2.8 MB\n",
      "    numpy-1.23.5               |   py38h47b59a4_1          11 KB\n",
      "    numpy-base-1.23.5          |   py38hcfaf2c3_1         5.8 MB\n",
      "    pillow-10.2.0              |   py38h6c40b1e_0         722 KB\n",
      "    pysocks-1.7.1              |           py38_1          27 KB\n",
      "    pytorch-2.2.0              |          py3.8_0        87.2 MB  pytorch\n",
      "    pyyaml-6.0.1               |   py38h6c40b1e_0         170 KB\n",
      "    requests-2.31.0            |   py38hecd8cb5_1         100 KB\n",
      "    sympy-1.12                 |   py38hecd8cb5_0        10.5 MB\n",
      "    torchaudio-2.2.0           |         py38_cpu         4.8 MB  pytorch\n",
      "    torchvision-0.17.0         |         py38_cpu         6.5 MB  pytorch\n",
      "    urllib3-2.1.0              |   py38hecd8cb5_1         154 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       302.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               pkgs/main/osx-64::blas-1.0-mkl \n",
      "  brotli-python      pkgs/main/osx-64::brotli-python-1.0.9-py38he9d5cce_7 \n",
      "  certifi            pkgs/main/osx-64::certifi-2024.2.2-py38hecd8cb5_0 \n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0 \n",
      "  filelock           pkgs/main/osx-64::filelock-3.13.1-py38hecd8cb5_0 \n",
      "  freetype           pkgs/main/osx-64::freetype-2.12.1-hd8bbffd_0 \n",
      "  gmp                pkgs/main/osx-64::gmp-6.2.1-he9d5cce_3 \n",
      "  gmpy2              pkgs/main/osx-64::gmpy2-2.1.2-py38hd5de756_0 \n",
      "  idna               pkgs/main/osx-64::idna-3.4-py38hecd8cb5_0 \n",
      "  intel-openmp       pkgs/main/osx-64::intel-openmp-2023.1.0-ha357a0b_43548 \n",
      "  jinja2             pkgs/main/osx-64::jinja2-3.1.3-py38hecd8cb5_0 \n",
      "  jpeg               pkgs/main/osx-64::jpeg-9e-h6c40b1e_1 \n",
      "  lcms2              pkgs/main/osx-64::lcms2-2.12-hf1fd2bf_0 \n",
      "  lerc               pkgs/main/osx-64::lerc-3.0-he9d5cce_0 \n",
      "  libdeflate         pkgs/main/osx-64::libdeflate-1.17-hb664fd8_1 \n",
      "  libjpeg-turbo      pkgs/main/osx-64::libjpeg-turbo-2.0.0-hca72f7f_0 \n",
      "  libpng             pkgs/main/osx-64::libpng-1.6.39-h6c40b1e_0 \n",
      "  libtiff            pkgs/main/osx-64::libtiff-4.5.1-hcec6c5f_0 \n",
      "  libwebp-base       pkgs/main/osx-64::libwebp-base-1.3.2-h6c40b1e_0 \n",
      "  lz4-c              pkgs/main/osx-64::lz4-c-1.9.4-hcec6c5f_0 \n",
      "  markupsafe         pkgs/main/osx-64::markupsafe-2.1.3-py38h6c40b1e_0 \n",
      "  mkl                pkgs/main/osx-64::mkl-2023.1.0-h8e150cf_43560 \n",
      "  mkl-service        pkgs/main/osx-64::mkl-service-2.4.0-py38h6c40b1e_1 \n",
      "  mkl_fft            pkgs/main/osx-64::mkl_fft-1.3.8-py38h6c40b1e_0 \n",
      "  mkl_random         pkgs/main/osx-64::mkl_random-1.2.4-py38ha357a0b_0 \n",
      "  mpc                pkgs/main/osx-64::mpc-1.1.0-h6ef4df4_1 \n",
      "  mpfr               pkgs/main/osx-64::mpfr-4.0.2-h9066e36_1 \n",
      "  mpmath             pkgs/main/osx-64::mpmath-1.3.0-py38hecd8cb5_0 \n",
      "  networkx           pkgs/main/osx-64::networkx-3.1-py38hecd8cb5_0 \n",
      "  numpy              pkgs/main/osx-64::numpy-1.23.5-py38h47b59a4_1 \n",
      "  numpy-base         pkgs/main/osx-64::numpy-base-1.23.5-py38hcfaf2c3_1 \n",
      "  openjpeg           pkgs/main/osx-64::openjpeg-2.4.0-h66ea3da_0 \n",
      "  pillow             pkgs/main/osx-64::pillow-10.2.0-py38h6c40b1e_0 \n",
      "  pysocks            pkgs/main/osx-64::pysocks-1.7.1-py38_1 \n",
      "  pytorch            pytorch/osx-64::pytorch-2.2.0-py3.8_0 \n",
      "  pyyaml             pkgs/main/osx-64::pyyaml-6.0.1-py38h6c40b1e_0 \n",
      "  requests           pkgs/main/osx-64::requests-2.31.0-py38hecd8cb5_1 \n",
      "  sympy              pkgs/main/osx-64::sympy-1.12-py38hecd8cb5_0 \n",
      "  tbb                pkgs/main/osx-64::tbb-2021.8.0-ha357a0b_0 \n",
      "  torchaudio         pytorch/osx-64::torchaudio-2.2.0-py38_cpu \n",
      "  torchvision        pytorch/osx-64::torchvision-0.17.0-py38_cpu \n",
      "  urllib3            pkgs/main/osx-64::urllib3-2.1.0-py38hecd8cb5_1 \n",
      "  yaml               pkgs/main/osx-64::yaml-0.2.5-haf1e3a3_0 \n",
      "  zstd               pkgs/main/osx-64::zstd-1.5.5-hc035e20_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch::pytorch torchvision torchaudio -c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (8.1.13)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (1.26.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (0.17.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (5.9.7)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/abdulmalikbintilas/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "model = YOLO('/Users/abdulmalikbintilas/Desktop/Flask/datsetDrone/best.pt')\n",
    "model1 = YOLO('/Users/abdulmalikbintilas/Desktop/Flask/weaponsdata/best.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1253248545.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    conda uninstall pytorch\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conda uninstall pytorch\n",
    "pip3 uninstall torch\n",
    "pip3 uninstall torch\n",
    "\n",
    "yolo detect val data='/Users/abdulmalikbintilas/Desktop/Flask/datasetDrone/data.yaml'  model='/Users/abdulmalikbintilas/Desktop/Flask/datasetDrone/best.pt'\n",
    "yolo detect val data='/Users/abdulmalikbintilas/Desktop/Flask/weaponsdata/data.yaml' model='/Users/abdulmalikbintilas/Desktop/Flask/weaponsdata/best.pt'\n",
    "pip install Flask torch torchvision Pillow\n",
    "pip install flask\n",
    "\n",
    "yolo detect val data='/Users/abdulmalikbintilas/Desktop/Flask/datsetDrone/data.yaml'  model='/Users/abdulmalikbintilas/Desktop/Flask/datsetDrone/best.pt'\n",
    "yolo detect val data='/Users/abdulmalikbintilas/Desktop/Flask/weaponsdata/data.yaml' model='/Users/abdulmalikbintilas/Desktop/Flask/weaponsdata/best.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /content: Read-only file system\n"
     ]
    }
   ],
   "source": [
    "cd /Users/abdulmalikbintilas/Desktop/Flask\n",
    "!mkdir -p /content/static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create templates folder\n",
    "os.makedirs(\"templates\", exist_ok=True)\n",
    "\n",
    "# Create index.html\n",
    "index_html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Object Detection</title>\n",
    "    <style>\n",
    "        body {\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            font-family: 'Arial', sans-serif;\n",
    "            background: url('https://i.ibb.co/tcJD33f/Adobe-Stock-571913299.jpg');\n",
    "            background-size: cover;\n",
    "            background-position: center;\n",
    "            color: #fff;\n",
    "            text-align: center;\n",
    "            padding-top: 5px;\n",
    "        }\n",
    "\n",
    "        h1 {\n",
    "            font-size: 2em;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "\n",
    "        p {\n",
    "            font-size: 1.2em;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "\n",
    "        button {\n",
    "            background-color: #4CAF50;\n",
    "            color: #fff;\n",
    "            padding: 10px 20px;\n",
    "            font-size: 1em;\n",
    "            margin: 5px;\n",
    "            cursor: pointer;\n",
    "            border: none;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "\n",
    "        button:hover {\n",
    "            background-color: #45a049;\n",
    "        }\n",
    "\n",
    "        #upload-form,\n",
    "        #capture-form {\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "\n",
    "        #live-feed {\n",
    "            width: 100%;\n",
    "            max-width: 640px;\n",
    "            height: auto;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Object Detection</h1>\n",
    "    \n",
    "    <p>Welcome to the object detection website. Choose one of the options below:</p>\n",
    "\n",
    "    <div>\n",
    "        <button id=\"upload-button\">Upload Image</button>\n",
    "        <button id=\"capture-button\">Capture Image with Camera</button>\n",
    "    </div>\n",
    "\n",
    "    <form id=\"upload-form\" action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\" style=\"display: none;\">\n",
    "        <label for=\"file\">Choose an image:</label>\n",
    "        <input type=\"file\" name=\"file\" accept=\"image/*\" required>\n",
    "        <button type=\"submit\">Upload and Detect</button>\n",
    "    </form>\n",
    "\n",
    "    <div id=\"camera-area\" style=\"display: none;\">\n",
    "        <video id=\"live-feed\" autoplay></video>\n",
    "        <button id=\"take-picture\">Take Picture</button>\n",
    "    </div>\n",
    "\n",
    "    <form id=\"capture-form\" action=\"/capture\" method=\"post\" style=\"display: none;\">\n",
    "        <input type=\"hidden\" name=\"captured_image\" id=\"captured-image-input\" required>\n",
    "        <button type=\"submit\">Detect Captured Image</button>\n",
    "    </form>\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    <!-- JavaScript to handle options and camera functionality -->\n",
    "    <script>\n",
    "        document.addEventListener('DOMContentLoaded', function() {\n",
    "            const uploadButton = document.getElementById('upload-button');\n",
    "            const captureButton = document.getElementById('capture-button');\n",
    "            const uploadForm = document.getElementById('upload-form');\n",
    "            const cameraArea = document.getElementById('camera-area');\n",
    "            const takePictureButton = document.getElementById('take-picture');\n",
    "            const captureForm = document.getElementById('capture-form');\n",
    "            const capturedImageInput = document.getElementById('captured-image-input');\n",
    "            const liveFeed = document.getElementById('live-feed');\n",
    "\n",
    "            let stream;  // Variable to store the camera stream\n",
    "\n",
    "            uploadButton.addEventListener('click', function() {\n",
    "                uploadForm.style.display = 'block';\n",
    "                cameraArea.style.display = 'none';\n",
    "            });\n",
    "\n",
    "            captureButton.addEventListener('click', function() {\n",
    "                uploadForm.style.display = 'none';\n",
    "                cameraArea.style.display = 'block';\n",
    "                startCamera();\n",
    "            });\n",
    "\n",
    "            takePictureButton.addEventListener('click', function() {\n",
    "                takePicture();\n",
    "            });\n",
    "\n",
    "            function startCamera() {\n",
    "                navigator.mediaDevices.getUserMedia({ video: true })\n",
    "                    .then(function (mediaStream) {\n",
    "                        stream = mediaStream;\n",
    "                        liveFeed.srcObject = mediaStream;\n",
    "                    })\n",
    "                    .catch(function (error) {\n",
    "                        console.error('Error accessing camera:', error.name, error.message);\n",
    "                    });\n",
    "            }\n",
    "\n",
    "            function takePicture() {\n",
    "                const canvas = document.createElement('canvas');\n",
    "                const context = canvas.getContext('2d');\n",
    "\n",
    "                canvas.width = liveFeed.videoWidth;\n",
    "                canvas.height = liveFeed.videoHeight;\n",
    "\n",
    "                context.drawImage(liveFeed, 0, 0, canvas.width, canvas.height);\n",
    "\n",
    "                // Convert the canvas to a data URL (base64-encoded) and set it as the value of the hidden input\n",
    "                const dataUrl = canvas.toDataURL('image/jpeg');\n",
    "                capturedImageInput.value = dataUrl.replace(/^data:image\\/(png|jpeg);base64,/, '');  // Remove the prefix\n",
    "\n",
    "                // Stop the video stream\n",
    "                stopCamera();\n",
    "\n",
    "                // Submit the form for image detection\n",
    "                captureForm.submit();\n",
    "            }\n",
    "\n",
    "            function stopCamera() {\n",
    "                if (stream) {\n",
    "                    stream.getTracks().forEach(track => track.stop());\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // Stop the video stream when the page is closed or refreshed\n",
    "            window.addEventListener('beforeunload', stopCamera);\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"templates/index.html\", \"w\") as file:\n",
    "    file.write(index_html_content)\n",
    "\n",
    "# Create result.html\n",
    "result_html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>YOLO Image Processor - Result</title>\n",
    "    <style>\n",
    "        body {\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            font-family: 'Arial', sans-serif;\n",
    "            background: url('https://i.ibb.co/tcJD33f/Adobe-Stock-571913299.jpg');\n",
    "            background-size: cover;\n",
    "            background-position: center;\n",
    "            color: #fff;\n",
    "            text-align: center;\n",
    "            padding-top: 50px;\n",
    "        }\n",
    "\n",
    "        h1 {\n",
    "            font-size: 2em;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "\n",
    "        img {\n",
    "            width: 100%;\n",
    "            max-width: 640px;\n",
    "            height: auto;\n",
    "            border: 2px solid #fff;\n",
    "            border-radius: 5px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "\n",
    "        p {\n",
    "            font-size: 1.2em;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "\n",
    "        a {\n",
    "            color: #4CAF50;\n",
    "            text-decoration: none;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "\n",
    "        a:hover {\n",
    "            color: #45a049;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Processed Image</h1>\n",
    "\n",
    "    <!-- Display the processed image -->\n",
    "    <img src=\"{{ 'static/result.jpg' }}\" alt=\"Processed Image\">\n",
    "\n",
    "    <p><a href=\"/\">Go back to upload</a></p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"templates/result.html\", \"w\") as file:\n",
    "    file.write(result_html_content)\n",
    "\n",
    "# Create capture.html\n",
    "capture_html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>YOLO Image Processor - Capture</title>\n",
    "    <style>\n",
    "        body {\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            font-family: 'Arial', sans-serif;\n",
    "            background: url('https://i.ibb.co/tcJD33f/Adobe-Stock-571913299.jpg');\n",
    "            background-size: cover;\n",
    "            background-position: center;\n",
    "            color: #fff;\n",
    "            text-align: center;\n",
    "            padding-top: 50px;\n",
    "        }\n",
    "\n",
    "        h1 {\n",
    "            font-size: 2em;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "\n",
    "        img {\n",
    "            width: 100%;\n",
    "            max-width: 640px;\n",
    "            height: auto;\n",
    "            border: 2px solid #fff;\n",
    "            border-radius: 5px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "\n",
    "        p {\n",
    "            font-size: 1.2em;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "\n",
    "        a {\n",
    "            color: #4CAF50;\n",
    "            text-decoration: none;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "\n",
    "        a:hover {\n",
    "            color: #45a049;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Capture Image</h1>\n",
    "\n",
    "    <!-- Display the captured image -->\n",
    "    <img src=\"{{ 'static/captured_image.jpg' }}\" alt=\"Captured Image\">\n",
    "\n",
    "    <p><a href=\"/\">Go back to upload</a></p>\n",
    "\n",
    "    <!-- Add any JavaScript code related to capturing image if needed -->\n",
    "\n",
    "    <script>\n",
    "        // Your JavaScript code can be added here if required\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"templates/capture.html\", \"w\") as file:\n",
    "    file.write(capture_html_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [29/Feb/2024 11:01:44] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Feb/2024 11:01:45] \"\u001b[33mGET /apple-touch-icon-precomposed.png HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [29/Feb/2024 11:01:45] \"\u001b[33mGET /apple-touch-icon.png HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [29/Feb/2024 11:01:45] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "model = YOLO('/Users/abdulmalikbintilas/Desktop/Flask/datsetDrone/best.pt')\n",
    "model1 = YOLO('/Users/abdulmalikbintilas/Desktop/Flask/weaponsdata/best.pt')\n",
    "from flask import Flask, render_template, request, send_from_directory\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import Image as IPImage, display\n",
    "import base64\n",
    "import io\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    " # Start ngrok when the app is run\n",
    "\n",
    "# Load YOLO models\n",
    "\n",
    "model = YOLO('/Users/abdulmalikbintilas/Desktop/Flask/datsetDrone/best.pt')\n",
    "model1 = YOLO('/Users/abdulmalikbintilas/Desktop/Flask/weaponsdata/best.pt')\n",
    "\n",
    "# Create the static directory if it doesn't exist\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/capture', methods=['GET', 'POST'])\n",
    "def capture():\n",
    "    if request.method == 'POST':\n",
    "        # Capture image from the camera\n",
    "        # You can use JavaScript to capture the image from the camera on the client side\n",
    "        # and send it to this route for processing\n",
    "        # For now, let's assume the captured image is sent as a base64-encoded string\n",
    "\n",
    "        # For demonstration purposes, you can decode the base64 string and save it as an image\n",
    "        base64_image = request.form['captured_image']\n",
    "        image_data = base64.b64decode(base64_image)\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        # Process the captured image (similar to the upload route)\n",
    "        results1 = model1(image)\n",
    "        results = model(image)\n",
    "\n",
    "        # Convert the image to OpenCV format\n",
    "        image_cv2 = cv2.cvtColor(results[0].orig_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Get the bounding boxes for drone model\n",
    "        boxes_drone = results[0].boxes.xyxy.tolist()\n",
    "        d = results[0].boxes.cls\n",
    "        f = d.numpy()\n",
    "\n",
    "        # Ensure f is not empty before accessing its elements\n",
    "        if len(f) > 0:\n",
    "            g = f[0]\n",
    "            ssss = results[0].names[g]\n",
    "\n",
    "        # Draw the bounding boxes for drone model on the image\n",
    "            for box in boxes_drone:\n",
    "                x1, y1, x2, y2 = box\n",
    "                cv2.rectangle(image_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                cv2.putText(image_cv2, str(ssss), (int(x1), int(y1) - 3), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        else:\n",
    "        # Handle the case when f is empty (no bounding box detected)\n",
    "             print(\"No bounding boxes detected for drone model\")\n",
    "        # You may want to set a default value for g or handle it accordingly\n",
    "\n",
    "        # Get the bounding boxes for weapons model\n",
    "        boxes_weapons = results1[0].boxes.xyxy.tolist()\n",
    "        a = results1[0].boxes.cls\n",
    "        b = a.numpy()\n",
    "\n",
    "        # Ensure b is not empty before accessing its elements\n",
    "        if len(b) > 0:\n",
    "          c = b[0]\n",
    "          sssss = results1[0].names[c]\n",
    "\n",
    "          for box in boxes_weapons:\n",
    "               x1, y1, x2, y2 = box\n",
    "               cv2.rectangle(image_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "               cv2.putText(image_cv2, str(sssss), (int(x1), int(y1) - 1), cv2.FONT_HERSHEY_SIMPLEX, 1, (150, 255, 0), 2)\n",
    "        else:\n",
    "        # Handle the case when b is empty\n",
    "              print(\"No bounding boxes detected for weapons model\")\n",
    "        # You may want to set a default value for c or handle it accordingly\n",
    "\n",
    "        \n",
    "\n",
    "         # Save the processed image in the static directory\n",
    "        image_path = 'static/captured_image.jpg'\n",
    "        cv2.imwrite(image_path, image_cv2)\n",
    "\n",
    "        # Display the processed image in the Colab notebook\n",
    "        display(IPImage(filename=image_path))\n",
    "\n",
    "        # Display the processed image in the HTML template\n",
    "        return render_template('capture.html', captured_image='static/captured_image.jpg')\n",
    "\n",
    "    return render_template('capture.html')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload():\n",
    "    if 'file' not in request.files:\n",
    "        return render_template('index.html', error='No file part')\n",
    "\n",
    "    file = request.files['file']\n",
    "\n",
    "    if file.filename == '':\n",
    "        return render_template('index.html', error='No selected file')\n",
    "\n",
    "    # Process the image with YOLO\n",
    "    image = Image.open(file)\n",
    "    results1 = model1(image)\n",
    "    results = model(image)\n",
    "\n",
    "    # Convert the image to OpenCV format\n",
    "    image_cv2 = cv2.cvtColor(results[0].orig_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Get the bounding boxes for drone model\n",
    "    boxes_drone = results[0].boxes.xyxy.tolist()\n",
    "    d = results[0].boxes.cls\n",
    "    f = d.numpy()\n",
    "\n",
    "    # Ensure f is not empty before accessing its elements\n",
    "    if len(f) > 0:\n",
    "        g = f[0]\n",
    "        ssss = results[0].names[g]\n",
    "\n",
    "        # Draw the bounding boxes for drone model on the image\n",
    "        for box in boxes_drone:\n",
    "            x1, y1, x2, y2 = box\n",
    "            cv2.rectangle(image_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(image_cv2, str(ssss), (int(x1), int(y1) - 1), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "    else:\n",
    "        # Handle the case when f is empty (no bounding box detected)\n",
    "        print(\"No bounding boxes detected for drone model\")\n",
    "        # You may want to set a default value for g or handle it accordingly\n",
    "\n",
    "    # Get the bounding boxes for weapons model\n",
    "    boxes_weapons = results1[0].boxes.xyxy.tolist()\n",
    "    a = results1[0].boxes.cls\n",
    "    b = a.numpy()\n",
    "\n",
    "    # Ensure b is not empty before accessing its elements\n",
    "    if len(b) > 0:\n",
    "        c = b[0]\n",
    "        sssss = results1[0].names[c]\n",
    "\n",
    "        for box in boxes_weapons:\n",
    "            x1, y1, x2, y2 = box\n",
    "            cv2.rectangle(image_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "            cv2.putText(image_cv2, str(sssss), (int(x1), int(y1) - 1), cv2.FONT_HERSHEY_SIMPLEX, 1, (150, 255, 0), 2)\n",
    "    else:\n",
    "        # Handle the case when b is empty\n",
    "        print(\"No bounding boxes detected for weapons model\")\n",
    "        # You may want to set a default value for c or handle it accordingly\n",
    "\n",
    "    # Save the processed image in the static directory\n",
    "    image_path = 'static/result.jpg'\n",
    "    cv2.imwrite(image_path, image_cv2)\n",
    "\n",
    "    # Display the processed image in the Colab notebook\n",
    "    display(IPImage(filename=image_path))\n",
    "\n",
    "    # Display the processed image in the HTML template\n",
    "    FinalImage = 'static/result.jpg'\n",
    "    return render_template('result.html', image_path=FinalImage)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
